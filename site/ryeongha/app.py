import streamlit as st
import time
import json
from PIL import Image
from yolo_detector import run_yolo_model

# ergonomics_analyzer.py íŒŒì¼ì—ì„œ ErgonomicsAnalyzer í´ë˜ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
# ì¤‘ìš”: ì´ íŒŒì¼ì„ ì‹¤í–‰í•˜ë ¤ë©´ ê°™ì€ í´ë”ì— ergonomics_analyzer.py íŒŒì¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
from ergonomics_analyzer import ErgonomicsAnalyzer
from steps.step2_object_detection import step2_object_detection

# --------------------------------------------------------------------------
# Streamlit UI êµ¬ì„±
# --------------------------------------------------------------------------

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="ì¸ì²´ê³µí•™ ìì„¸ ë¶„ì„ ì„œë¹„ìŠ¤",
    page_icon="ğŸ¦¾",
    layout="centered"
)

# --- ì‚¬ì´ë“œë°” (ì‚¬ìš©ì ì…ë ¥) ---
with st.sidebar:
    st.header("ğŸ‘¤ ì‚¬ìš©ì ì •ë³´ ì…ë ¥")
    user_height = st.number_input("í‚¤(cm)", min_value=100, max_value=250, value=175)
    gender = st.selectbox("ì„±ë³„", ["male", "female"])
    handedness = st.radio("ì£¼ ì‚¬ìš© ì†", ["ì˜¤ë¥¸ì†ì¡ì´", "ì™¼ì†ì¡ì´"])

    st.header("ğŸ–¥ï¸ ìŠ¤í¬ë¦° ì •ë³´ ì…ë ¥")
    main_screen_inch = st.text_input("ë©”ì¸ ìŠ¤í¬ë¦° í¬ê¸° (ì¸ì¹˜)", value="27ì¸ì¹˜")

# --- ë©”ì¸ í˜ì´ì§€ ---
st.title("ì¸ì²´ê³µí•™ ìì„¸ ë¶„ì„ ì„œë¹„ìŠ¤ ğŸ¦¾")
st.write("ì‘ì—… í™˜ê²½ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì—¬ ì¸ì²´ê³µí•™ì  ë¬¸ì œì ì„ ë¶„ì„í•˜ê³  í•´ê²°ì±…ì„ ë°›ì•„ë³´ì„¸ìš”.")

uploaded_file = st.file_uploader(
    "ë¶„ì„í•  ì‚¬ì§„ì„ ì—¬ê¸°ì— ì—…ë¡œë“œí•˜ì„¸ìš”.",
    type=['png', 'jpg', 'jpeg']
)

if uploaded_file is not None:
    # 2ë‹¨ê³„ í•¨ìˆ˜ í˜¸ì¶œ
    result = step2_object_detection(uploaded_file)

    if result:
        # ì‚¬ìš©ìê°€ ìŠ¤í¬ë¦° ì„ íƒí•˜ê³  'ë¶„ì„ ì‹œì‘' ëˆŒë €ì„ ë•Œ ì‹¤í–‰ë¨
        selected_id = result["screen_id"]
        main_screen_inch = result["inch"]
        yolo_output = result["yolo_output"]

        # ì‚¬ìš©ì ì…ë ¥ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        user_inputs = {
            "user_height_cm": user_height,
            "gender": gender,
            "handedness": handedness,
        }
        analyzer = ErgonomicsAnalyzer(yolo_output, user_inputs)
        analyzer.set_main_screen_by_id(selected_id, main_screen_inch)

        # ë¶„ì„ ì‹¤í–‰
        report = analyzer.run_all_analyses()
        st.success("ë¶„ì„ ì™„ë£Œ âœ…")
        st.json(report)

        # --- 4. ë¶„ì„ ì‹œì‘ ë²„íŠ¼ ---
        if st.button("ì„ íƒí•œ ìŠ¤í¬ë¦°ìœ¼ë¡œ ìì„¸ ë¶„ì„ ì‹œì‘í•˜ê¸°"):
            with st.spinner("ì„ íƒëœ ìŠ¤í¬ë¦°ì„ ê¸°ì¤€ìœ¼ë¡œ ìì„¸ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                # 4-1. ì‚¬ìš©ìê°€ ì„ íƒí•œ ìŠ¤í¬ë¦°ì„ ë©”ì¸ ìŠ¤í¬ë¦°ìœ¼ë¡œ ì„¤ì •
                selected_id = screen_options[selected_option]
                analyzer.set_main_screen_by_id(selected_id, main_screen_inch)

                # 4-2. ì‹¤ì œ ë¶„ì„ ì‹¤í–‰
                report = analyzer.run_all_analyses()

                # 4-3. (ê°€ìƒ) GPTì—ê²Œ ì†”ë£¨ì…˜ ìš”ì²­
                # ì‹¤ì œ êµ¬í˜„: solution_text = ask_gpt_for_solution(report)
                solution_text = f"""
                ###  ì¢…í•© ë¶„ì„ ê²°ê³¼ (ë©”ì¸ ìŠ¤í¬ë¦°: {selected_option})
                ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì£¼ìš” ë¬¸ì œì ê³¼ í•´ê²°ì±…ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

                (ì´ ë¶€ë¶„ì€ ì‹¤ì œ GPTê°€ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„±í•  ë™ì  ê²°ê³¼ì…ë‹ˆë‹¤.)

                - **ë¬¸ì œì  1**: ...
                - **ë¬¸ì œì  2**: ...
                """

            # 4-4. ìµœì¢… ê²°ê³¼ ì¶œë ¥
            st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.markdown(solution_text)

            with st.expander("ìì„¸í•œ ë¶„ì„ ë¦¬í¬íŠ¸ ë³´ê¸° (JSON)"):
                st.json(report)
