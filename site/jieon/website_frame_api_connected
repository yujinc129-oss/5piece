# app.py
# -*- coding: utf-8 -*-
"""
ì¸ì²´ê³µí•™ì  ì±…ìƒ ê°œì„  ê°€ì´ë“œ (Streamlit)
- ê¸°ì¡´ UI/í˜ì´ì§€ íë¦„ ìœ ì§€
- OpenAI GPT ì—°ë™ (í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY í•„ìš”)
- ì‹¤í–‰: streamlit run app.py
"""
import os
import time
import logging
from typing import Optional, Tuple, Dict

import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI

# ---------------------------
# ì„¤ì • ë° ë¡œê¹…
# ---------------------------
load_dotenv()  # ë¡œì»¬ ê°œë°œì‹œ .env ìë™ ë¡œë“œ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ---------------------------
# OpenAI ì•ˆì „ ì´ˆê¸°í™” ìœ í‹¸
# ---------------------------
def make_openai_client() -> Optional[OpenAI]:
    key = os.environ.get("OPENAI_API_KEY")
    if not key:
        return None
    try:
        return OpenAI(api_key=key)
    except Exception:
        logger.exception("OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨")
        return None

def api_key_status_text() -> str:
    key = os.environ.get("OPENAI_API_KEY")
    return f"âœ… ì„¤ì •ë¨ (í‚¤ ì‹œì‘: {key[:6]}...)" if key else "âš ï¸ ì„¤ì •ë˜ì§€ ì•ŠìŒ!"

def extract_text_from_response(resp) -> str:
    try:
        if hasattr(resp, "choices") and len(resp.choices) > 0:
            choice = resp.choices[0]
            if hasattr(choice, "message") and hasattr(choice.message, "content"):
                return choice.message.content.strip()
            if hasattr(choice, "text"):
                return choice.text.strip()
            if isinstance(choice, dict):
                msg = choice.get("message") or {}
                if isinstance(msg, dict) and msg.get("content"):
                    return msg["content"].strip()
        if isinstance(resp, dict):
            choices = resp.get("choices", [])
            if choices:
                c0 = choices[0]
                if isinstance(c0, dict):
                    msg = c0.get("message") or {}
                    content = msg.get("content") or c0.get("text")
                    if content:
                        return content.strip()
    except Exception:
        logger.exception("ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜")
    return "ì‘ë‹µì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# ì „ì—­ í´ë¼ì´ì–¸íŠ¸ (ëŸ°íƒ€ì„ì— ì¬ì´ˆê¸°í™” ê°€ëŠ¥)
client: Optional[OpenAI] = make_openai_client()

# ---------------------------
# ë°ì´í„° í´ë˜ìŠ¤ ë° ë¶„ì„ ë¡œì§ (ì›ë³¸ ìœ ì§€)
# ---------------------------
class UserAnalysis:
    def __init__(self, monitor_size: int = 24, height_cm: int = 170):
        self.monitor_size = monitor_size
        self.height_cm = height_cm

    def to_dict(self) -> Dict:
        return {"monitor_size": self.monitor_size, "height_cm": self.height_cm}

def mock_run_analysis_pipeline(user_analysis: UserAnalysis) -> Tuple[str, Dict]:
    monitor_size = user_analysis.monitor_size
    height_cm = user_analysis.height_cm
    if monitor_size >= 27 and height_cm >= 175:
        result = "âœ… í˜„ì¬ ì±…ìƒ êµ¬ì„±ì€ ëŒ€ì²´ë¡œ ì¸ì²´ê³µí•™ì  ê¸°ì¤€ì— ì í•©í•©ë‹ˆë‹¤."
    else:
        result = "âš ï¸ ì±…ìƒ ë†’ì´ ë˜ëŠ” ëª¨ë‹ˆí„° í¬ê¸° ì¡°ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    report = {
        "monitor_size": monitor_size,
        "height_cm": height_cm,
        "recommendation": result,
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
    }
    return result, report

# ---------------------------
# OpenAI ì—°ë™ í•¨ìˆ˜
# ---------------------------
def get_gpt_recommendation(report: Dict) -> str:
    global client
    if not client:
        client = make_openai_client()
    if not client:
        return "âš ï¸ OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. OPENAI_API_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”."

    prompt_text = (
        f"ì‚¬ìš©ìì˜ ì±…ìƒ í™˜ê²½ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:\n"
        f"- ëª¨ë‹ˆí„° í¬ê¸°: {report['monitor_size']} ì¸ì¹˜\n"
        f"- ì‚¬ìš©ì ì‹ ì¥: {report['height_cm']} cm\n"
        f"- 1ì°¨ ì§„ë‹¨: {report['recommendation']}\n\n"
        "ë‹¹ì‹ ì€ ì„¸ê³„ ìµœê³ ì˜ ì¸ì²´ê³µí•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ë§¤ìš° êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì±…ìƒ í™˜ê²½ ê°œì„  ë°©ì•ˆì„ í•œêµ­ì–´ë¡œ "
        "ë²ˆí˜¸ ëª©ë¡ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”. ë‹¤ìŒì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”: 1) í˜„ì¬ ìƒí™© ì§„ë‹¨ 2) ëª¨ë‹ˆí„° ì„¤ì • ê°€ì´ë“œ 3) ì±…ìƒ ë° ì˜ì ë†’ì´ ì¡°ì–¸ 4) ì¶”ê°€ì ì¸ ì¸ì²´ê³µí•™ íŒ."
    )

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a world-class ergonomics expert, answer in Korean."},
                {"role": "user", "content": prompt_text}
            ],
            temperature=0.7,
            max_tokens=600,
            timeout=30
        )
        return extract_text_from_response(response)
    except Exception as e:
        logger.exception("GPT í˜¸ì¶œ ì‹¤íŒ¨")
        return f"GPT API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# ---------------------------
# í˜ì´ì§€ íë¦„ ì œì–´ í—¬í¼
# ---------------------------
def go_to_page(page_num: int):
    st.session_state['current_page'] = page_num
    st.rerun()

def handle_retry():
    st.session_state['current_page'] = 1
    st.session_state['user_analysis'] = UserAnalysis()
    st.session_state['analysis_result'] = None
    st.session_state['detailed_report'] = None
    st.rerun()

# ---------------------------
# í˜ì´ì§€ë³„ ì½˜í…ì¸  (ì›ë³¸ êµ¬ì¡° ìœ ì§€)
# ---------------------------
def page1_content():
    st.image("https://via.placeholder.com/600x200.png?text=Ergonomic+Desk+Guide")
    st.subheader("ğŸ“ ì¸ì²´ê³µí•™ì  ì±…ìƒ ê°œì„  ê°€ì´ë“œ")
    st.markdown("ì´ ì„œë¹„ìŠ¤ëŠ” ì‚¬ìš©ìì˜ ì±…ìƒ í™˜ê²½ê³¼ ì‹ ì²´ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¸ì²´ê³µí•™ì  ê°œì„  ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
    st.markdown("---")
    st.info(f"OpenAI API í‚¤ ìƒíƒœ: {api_key_status_text()}")

def page2_content():
    st.subheader("ğŸ–¥ï¸ ì±…ìƒ ë° ëª¨ë‹ˆí„° ì •ë³´ ì…ë ¥")
    monitor_size = st.slider("ëª¨ë‹ˆí„° í¬ê¸° (inch)", 19, 49, st.session_state['user_analysis'].monitor_size)
    st.session_state['user_analysis'].monitor_size = monitor_size

def page3_content():
    st.subheader("ğŸ§ ì‚¬ìš©ì ì‹ ì²´ ì •ë³´ ì…ë ¥")
    height_cm = st.number_input("ì‹ ì¥ (cm)", min_value=100, max_value=220, value=st.session_state['user_analysis'].height_cm)
    st.session_state['user_analysis'].height_cm = height_cm

def page4_analysis_in_progress():
    st.header("Page 4: â±ï¸ ë¶„ì„ ì§„í–‰ ì¤‘...")
    st.info("ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. ì™„ë£Œ ì‹œ P5ë¡œ ìë™ ì „í™˜ë©ë‹ˆë‹¤.")
    st.image("https://via.placeholder.com/600x200.png?text=Analyzing...")
    with st.spinner("ë¶„ì„ ì¤‘..."):
        time.sleep(1)
        final_solution_text, analysis_report = mock_run_analysis_pipeline(st.session_state['user_analysis'])
        st.success("ê¸°ë³¸ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        time.sleep(0.5)
    st.session_state['analysis_result'] = final_solution_text
    st.session_state['detailed_report'] = analysis_report

    st.markdown("---")
    st.info("ì›í•˜ë©´ AI(GPT) ê¶Œì¥ì‚¬í•­ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ ì‘ë™í•©ë‹ˆë‹¤.")
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ìƒì„±: AI ê¶Œì¥ì‚¬í•­ ë°›ê¸° (P5ë¡œ ì´ë™)", key="gpt_generate"):
            with st.spinner("AI ê¶Œì¥ì‚¬í•­ ìƒì„± ì¤‘..."):
                gpt_text = get_gpt_recommendation(st.session_state['detailed_report'])
                st.session_state['analysis_result'] = gpt_text
                go_to_page(5)
    with col2:
        if st.button("ê±´ë„ˆë›°ê¸°: ê²°ê³¼ë§Œ ë³´ê¸° (P5ë¡œ ì´ë™)", key="skip_gpt"):
            go_to_page(5)

def page5_content():
    final_result = st.session_state.get('analysis_result', "ë¶„ì„ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    detailed_report = st.session_state.get('detailed_report', {"error": "No report found"})
    st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")
    st.success(final_result)
    st.markdown("### ğŸ“‹ ìƒì„¸ ë¦¬í¬íŠ¸")
    st.json(detailed_report)
    st.markdown("---")
    if st.button("Retry Service (P1ë¡œ ì´ˆê¸°í™”)", key="retry_p5", use_container_width=True):
        handle_retry()

# ---------------------------
# Streamlit ì´ˆê¸° ì„¤ì • ë° ë©”ì¸ ë£¨í”„
# ---------------------------
st.set_page_config(page_title="ì¸ì²´ê³µí•™ì  ì±…ìƒ ê°œì„  ê°€ì´ë“œ", page_icon="ğŸ¦¾", layout="centered")
st.title("ğŸ¦¾ ì¸ì²´ê³µí•™ì  ì±…ìƒ ê°œì„  ê°€ì´ë“œ ì„œë¹„ìŠ¤")
st.markdown("---")

if 'current_page' not in st.session_state:
    st.session_state['current_page'] = 1
if 'user_analysis' not in st.session_state:
    st.session_state['user_analysis'] = UserAnalysis()
if 'analysis_result' not in st.session_state:
    st.session_state['analysis_result'] = None
if 'detailed_report' not in st.session_state:
    st.session_state['detailed_report'] = None

def display_page():
    page = st.session_state['current_page']
    if page == 1:
        page1_content()
        if st.button("Start Analysis (P2ë¡œ ì´ë™)", key="start_p1", use_container_width=True):
            go_to_page(2)
    elif page == 2:
        page2_content()
        st.markdown("---")
        if st.button("Next > (P3ë¡œ ì´ë™)", key="next_p2", use_container_width=True):
            go_to_page(3)
    elif page == 3:
        page3_content()
        st.markdown("---")
        col_return, col_next = st.columns(2)
        with col_return:
            if st.button("< Return (P2ë¡œ íšŒê·€)", key="return_p3", use_container_width=True):
                go_to_page(2)
        with col_next:
            if st.button("Analyze Desk > (P4ë¡œ ì´ë™)", key="next_p3", use_container_width=True):
                go_to_page(4)
    elif page == 4:
        page4_analysis_in_progress()
    elif page == 5:
        page5_content()

display_page()
